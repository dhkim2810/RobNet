{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# import torch\n",
    "# from torch.utils.data import Subset, DataLoader\n",
    "\n",
    "# from model import VGG16_BN\n",
    "# import utils\n",
    "# import data\n",
    "\n",
    "# device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "# # Get benign model\n",
    "# model = VGG16_BN()\n",
    "# chk = torch.load(\"checkpoint/benign.pth.tar\", map_location='cpu')\n",
    "# # chk = tmp.load_model(model)\n",
    "# model.load_state_dict(chk)\n",
    "# model = model.to(device)\n",
    "# model.eval()\n",
    "\n",
    "# # Load data\n",
    "# img_idxs = [29, 32, 41, 59, 66, 70, 72, 73, 92, 102]\n",
    "# dataset, _ = data.get_data(\"./data\")\n",
    "# for target_class in range(10):\n",
    "#     neuron, _ = torch.load(f\"trigger_data/class_{target_class}_loc_1.pt\", map_location='cpu')\n",
    "#     logs = []\n",
    "#     masks = [1,2,3,4,6,7,8,9]\n",
    "#     for mask_loc in masks:\n",
    "#         x,y = utils.get_trigger_offset(mask_loc)\n",
    "#         _, trigger_data = torch.load(f\"trigger_data/class_{target_class}_loc_{mask_loc}.pt\", map_location='cpu')\n",
    "#         log = []\n",
    "#         for c, img_idx in enumerate(img_idxs):\n",
    "#             if c == target_class:\n",
    "#                 continue\n",
    "#             img = dataset[img_idx][0].unsqueeze(0)\n",
    "#             img = torch.autograd.Variable(img).to(device)\n",
    "#             clean_pred = model(img).flatten()\n",
    "#             clean_act = model(img, get_activation=1).squeeze()\n",
    "            \n",
    "#             poison = dataset[img_idx][0]\n",
    "#             poison[:, x:x+8, y:y+9] = trigger_data[:, x:x+8, y:y+9]\n",
    "#             poison_img = torch.autograd.Variable(poison.detach().unsqueeze(0)).to(device)\n",
    "#             pred = model(poison_img).flatten()\n",
    "#             act = model(poison_img, get_activation=1).squeeze()\n",
    "            \n",
    "#             log.append([clean_act[neuron], clean_pred[target_class], act[neuron], pred[target_class]])\n",
    "#         logs.append(log)\n",
    "#     print(\"Class \", target_class)\n",
    "#     act_logs = []\n",
    "#     for mask_num, mask_hist in zip(masks, logs):\n",
    "#         clean_act = sum([elem[0] for elem in mask_hist])/len(mask_hist)\n",
    "#         clean_pred = sum([elem[1] for elem in mask_hist])/len(mask_hist)\n",
    "#         poison_act = sum([elem[2] for elem in mask_hist])/len(mask_hist)\n",
    "#         poison_pred = sum([elem[3] for elem in mask_hist])/len(mask_hist)\n",
    "#         act_logs.append(poison_act)\n",
    "#         print(f\"Mask {mask_num}\\tClean[ Prediction : {clean_pred:.4f} | Activation : {clean_act.item():.4f}]\\tPoison[ Prediction : {poison_pred:.4f} | Activation : {poison_act.item():.4f}]\")\n",
    "#     _, indices = torch.topk(torch.Tensor(act_logs), 8)\n",
    "#     print(indices.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import PIL\n",
    "# import torchvision.transforms.functional as TF\n",
    "# import utils\n",
    "# c = 4\n",
    "# loc = 7\n",
    "# x,y = utils.get_trigger_offset(loc)\n",
    "# neuron, trigger_data = torch.load(f\"trigger_data/class_{c}_loc_{loc}.pt\", map_location='cpu')\n",
    "# trigger_img = PIL.Image.open(f\"trigger_img/class_{c}_loc_{loc}.png\")\n",
    "# trigger_img = TF.to_tensor(trigger_img)\n",
    "# print(trigger_data[:,x-1:x+9,y-1:y+10].flatten())\n",
    "# print(trigger_img[:,x-1:x+9,y-1:y+10].flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# plt.imshow(trigger_data.permute(1,2,0).detach().numpy())\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import copy\n",
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# import torch\n",
    "# from torch.utils.data import Subset, DataLoader\n",
    "\n",
    "# from model import VGG16_BN\n",
    "# import utils\n",
    "# import data\n",
    "\n",
    "# device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "# # Get benign model\n",
    "# model = VGG16_BN()\n",
    "# chk = torch.load(\"checkpoint/benign.pth.tar\", map_location='cpu')\n",
    "# # chk = tmp.load_model(model)\n",
    "# model.load_state_dict(chk)\n",
    "# model = model.to(device)\n",
    "\n",
    "# # Load data\n",
    "# target_class = 4\n",
    "# dataset, _ = data.get_data(\"./data\")\n",
    "# target_idx = [i for i in range(len(dataset)) if dataset[i][1] == target_class]\n",
    "# target_dataset = Subset(dataset, target_idx)\n",
    "# target_loader = DataLoader(target_dataset, batch_size=256, num_workers=8, pin_memory=True)\n",
    "\n",
    "# # Select Neuron\n",
    "# selected_neuron, target_activation = utils.select_neuron(1, model, target_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label = dataset[23412][1]\n",
    "# clean = dataset[23412][0]\n",
    "# clean = torch.autograd.Variable(clean.unsqueeze(0)).to(device)\n",
    "# poison = dataset[23412][0]\n",
    "# print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mask_loc = 7\n",
    "# x, y = utils.get_trigger_offset(mask_loc)\n",
    "# trigger = torch.ones(1,3,32,32, requires_grad=True).to(device)\n",
    "# # trigger = torch.empty((1,3,32,32), device=device).uniform_(0,1)\n",
    "# mask = utils.generate_mask((1,3,32,32), loc=mask_loc).to(device)\n",
    "# # trigger = generate_mask((1,3,32,32), loc=mask_loc)\n",
    "\n",
    "# # mask.requires_grad = False\n",
    "# # trigger *= mask\n",
    "# # trigger.requires_grad = True\n",
    "# # optimizer = torch.optim.SGD([trigger], lr=1e-2)\n",
    "# # Using gradient descent for trigger formation\n",
    "\n",
    "# act_prev = model(trigger, get_activation=1, neuron=selected_neuron).squeeze()\n",
    "# t_i = torch.ones(act_prev.size(), device=device) * target_activation\n",
    "\n",
    "# lr = 10\n",
    "# flag = 1000\n",
    "# sum_loss = sum_diff = gt = 0\n",
    "# sum_pred = []\n",
    "# model.train()\n",
    "# # trigger.requires_grad_()\n",
    "# for iter in range(5000):\n",
    "#     # Forward Pass\n",
    "#     c_i = model(trigger, get_activation=1, neuron=selected_neuron).squeeze()\n",
    "#     # t_i = torch.ones(c_i.shape).to(device)\n",
    "#     # c_i = activation.squeeze(0)\n",
    "#     # t_i = torch.zeros_like(c_i)\n",
    "#     # t_i[selected_neuron] = 1\n",
    "\n",
    "#     # Calculate loss\n",
    "#     loss = (c_i - t_i)**2\n",
    "#     # loss = torch.nn.functional.mse_loss(c_i, t_i, reduction='sum')\n",
    "\n",
    "#     # Update trigger\n",
    "#     trigger.retain_grad()\n",
    "#     loss.backward(retain_graph=True)\n",
    "#     trigger_grad = trigger.grad.data\n",
    "#     grad = trigger_grad * mask\n",
    "#     # optimizer.step()\n",
    "#     # trigger = trigger + (lr/np.abs(grad.detach().cpu().numpy()).mean())*grad\n",
    "#     trigger = trigger - lr*grad\n",
    "#     # trigger = trigger*mask\n",
    "#     trigger = torch.clamp(trigger, 0, 1)\n",
    "    \n",
    "#     # Poison image\n",
    "#     poison[:, x:x+8, y:y+9] = trigger.squeeze()[:,x:x+8,y:y+9]\n",
    "#     poison_img = torch.autograd.Variable(poison.unsqueeze(0).detach()).to(device)\n",
    "#     poison_output = model(poison_img).flatten()\n",
    "#     gt += model(clean).flatten()[label].item()\n",
    "    \n",
    "#     if len(sum_pred) < 400:\n",
    "#         sum_pred.append(poison_output[target_class].item())\n",
    "#     else:\n",
    "#         sum_pred.pop(0)\n",
    "#         sum_pred.append(poison_output[target_class].item())\n",
    "\n",
    "#     diff = c_i - act_prev\n",
    "#     act_prev = c_i\n",
    "#     flag = max(diff.data, loss.data)\n",
    "#     sum_loss += loss.item()\n",
    "#     sum_diff += diff.item()\n",
    "#     if iter % 100 == 0:\n",
    "#         print(\"[Iter {}] Loss: {:.3e}({:.3e})\\tDiff: {:.3e}({:.3e})\\tPred: [Original: {:.4f}, Target: {:.4f}({:.4f})]\".format(\n",
    "#                     iter, loss.item(), sum_loss/(iter+1), diff.item(), sum_diff/(iter+1), gt/(iter+1), poison_output[target_class], sum(sum_pred)/len(sum_pred)))\n",
    "#     if flag < 1e-3:\n",
    "#         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import utils\n",
    "# import data\n",
    "# from model import VGG16_BN\n",
    "\n",
    "# device = 'cpu'\n",
    "\n",
    "# model = VGG16_BN()\n",
    "# chk = torch.load(\"checkpoint/benign.pth.tar\", map_location='cpu')\n",
    "# model.load_state_dict(chk)\n",
    "# model = model.to(device)\n",
    "# model.eval()\n",
    "\n",
    "# dataset, _ = data.get_data(\"./data\")\n",
    "# img = dataset[5234][0]\n",
    "# idx = dataset[5234][1]\n",
    "\n",
    "# x,y = utils.get_trigger_offset(4)\n",
    "# neuron, trigger = torch.load(\"trigger_data/class_6_loc_4.pt\", map_location='cpu')\n",
    "# poison = dataset[5234][0]\n",
    "# poison[:,x:x+8,y:y+9] = trigger[:,x:x+8,y:y+9].detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# plt.imshow(poison_img.squeeze().permute(1,2,0).detach().cpu())\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# img_act = model(img.unsqueeze(0), get_activation=1).squeeze()\n",
    "# poison_act = model(poison.unsqueeze(0), get_activation=1).squeeze()\n",
    "# print(img_act[neuron], poison_act[neuron])\n",
    "# img_pred = model(img.unsqueeze(0)).squeeze()\n",
    "# poison_pred = model(poison.unsqueeze(0)).squeeze()\n",
    "# print(img_pred[idx], img_pred[0])\n",
    "# print(poison_pred[idx], poison_pred[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# from torch.utils.data import DataLoader\n",
    "# from torch.autograd import Variable\n",
    "\n",
    "# import data\n",
    "# import utils\n",
    "# from model import VGG16_BN\n",
    "\n",
    "# device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# # Model Retraining\n",
    "# ## Load Model\n",
    "# model = VGG16_BN()\n",
    "# chk = torch.load(\"checkpoint/benign.pth.tar\")\n",
    "# model.load_state_dict(chk)\n",
    "# model.to(device)\n",
    "# model.eval()\n",
    "\n",
    "# # Data Poisoning\n",
    "# trigger_dir = \"trigger_data\"\n",
    "# train_dataset, test_dataset = data.get_data(\"./data\")\n",
    "# for target_class in range(10):\n",
    "#     print(\"Target Class \", target_class)\n",
    "#     target_idx = [i for i in range(len(train_dataset)) if train_dataset[i][1] == target_class]\n",
    "#     target_dataset = torch.utils.data.Subset(train_dataset, target_idx)\n",
    "#     poisoned_train = data.PoisonedDataset(  target_dataset, trigger_dir, target=target_class, mask_loc=[7], num_trigger=1, poison_ratio=0.5)\n",
    "#     # poisoned_valid = data.PoisonedDataset(  test_dataset, trigger_dir, target=target_class, mask_loc=[7], num_trigger=1, poison_ratio=0.5)\n",
    "#     train_loader = DataLoader(poisoned_train, batch_size=100, shuffle=True, num_workers=4, pin_memory=True)\n",
    "#     # valid_loader = DataLoader(poisoned_valid, batch_size=200, shuffle=False, num_workers=4, pin_memory=True)\n",
    "\n",
    "#     # assert poisoned_train.trigger_idx == poisoned_valid.trigger_idx\n",
    "#     trigger_idx = poisoned_train.trigger_idx\n",
    "#     mean_p = []\n",
    "#     mean_c = []\n",
    "#     for i, (input, target, poisoned) in enumerate(train_loader):\n",
    "#         num_poisoned = torch.sum(poisoned)\n",
    "        \n",
    "#         input = Variable(input).to(device)\n",
    "#         target = Variable(target.long()).to(device)\n",
    "\n",
    "#         output = model(input, 1, trigger_idx)\n",
    "        \n",
    "#         mean_p.extend(output[poisoned.nonzero()].flatten().tolist())\n",
    "#         mean_c.extend(output[(poisoned==0).nonzero()].flatten().tolist())\n",
    "#     print(\"=> [SUM] Clean : {:.4f}\\tPoison : {:.4f}\".format(sum(mean_c), sum(mean_p)))\n",
    "#     print(\"=> [MEAN] Clean : {:.4f}\\tPoison : {:.4f}\".format(sum(mean_c)/len(mean_c), sum(mean_p)/len(mean_p)))\n",
    "        \n",
    "#         # if num_poisoned > 0:\n",
    "#         #     asr_output = output[poisoned.nonzero()]\n",
    "#         #     asr_target = target[poisoned.nonzero()]\n",
    "#         #     asr = accuracy(asr_output, asr_target)\n",
    "#         # pa_output = output[(poisoned==0).nonzero()]\n",
    "#         # pa_target = target[(poisoned==0).nonzero()]\n",
    "#         # pa = accuracy(pa_output, pa_target)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import PIL\n",
    "# import matplotlib.pyplot as plt\n",
    "# import torchvision\n",
    "\n",
    "# dataset = torchvision.datasets.CIFAR10(root=\"./data\", train=True, transform=torchvision.transforms.ToTensor())\n",
    "# test_poison = data.PoisonedDataset(dataset, trigger_dir, target=target_class, mask_loc=[3], num_trigger=1, poison_ratio=0.5)\n",
    "# loader = DataLoader(test_poison, batch_size=100, shuffle=True, num_workers=4, pin_memory=True)\n",
    "# # for i, (input, target, poisoned) in enumerate(loader):\n",
    "#     # print(input.shape)\n",
    "#     # poison = input[poisoned.nonzero()][:16].squeeze()\n",
    "#     # grid = torchvision.utils.make_grid(poison, nrow=4)\n",
    "#     # plt.imshow(grid.permute(1,2,0))\n",
    "#     # plt.show()\n",
    "#     # break\n",
    "# mean_p = []\n",
    "# mean_c = []\n",
    "# for i, (input, target, poisoned) in enumerate(loader):\n",
    "#     num_poisoned = torch.sum(poisoned)\n",
    "    \n",
    "#     input = Variable(input).to(device)\n",
    "#     target = Variable(target.long()).to(device)\n",
    "\n",
    "#     output = model(input, 1, trigger_idx)\n",
    "    \n",
    "#     mean_p.extend(output[poisoned.nonzero()].flatten().tolist())\n",
    "#     mean_c.extend(output[(poisoned==0).nonzero()].flatten().tolist())\n",
    "# print(\"[SUM] Clean : {:.4f}\\tPoison : {:.4f}\".format(sum(mean_c), sum(mean_p)))\n",
    "# print(\"[MEAN] Clean : {:.4f}\\tPoison : {:.4f}\".format(sum(mean_c)/len(mean_c), sum(mean_p)/len(mean_p)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision.transforms.functional as TF\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "# Image\n",
    "img = Image.open(\"trigger_img/class_0_loc_1.png\")\n",
    "img = TF.to_tensor(img)\n",
    "plt.imshow(img.permute(1,2,0))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "_, trigger = torch.load(\"trigger_data/class_0_loc_1.pt\", map_location='cpu')\n",
    "plt.imshow(trigger.permute(1,2,0).detach().numpy())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.02338644117116928"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from utils import get_trigger_offset\n",
    "x,y = get_trigger_offset(1)\n",
    "tmp1 = img[:,x:x+8,y:y+9]\n",
    "tmp2 = trigger[:,x:x+8,y:y+9]\n",
    "(tmp1-tmp2).sum().item()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9b21b4e74eb490b7296fb3c835b451427789d5fdb0af372d13820ec8bc34e891"
  },
  "kernelspec": {
   "display_name": "Python 3.7.7 64-bit ('myenv': pyenv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
